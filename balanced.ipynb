{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from itertools import combinations\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import random\n",
    "random.seed(100)\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Race</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>T Stage</th>\n",
       "      <th>N Stage</th>\n",
       "      <th>6th Stage</th>\n",
       "      <th>differentiate</th>\n",
       "      <th>Grade</th>\n",
       "      <th>A Stage</th>\n",
       "      <th>Tumor Size</th>\n",
       "      <th>Estrogen Status</th>\n",
       "      <th>Progesterone Status</th>\n",
       "      <th>Regional Node Examined</th>\n",
       "      <th>Reginol Node Positive</th>\n",
       "      <th>Survival Months</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>3</td>\n",
       "      <td>Regional</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T2</td>\n",
       "      <td>N2</td>\n",
       "      <td>IIIA</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>35</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>T3</td>\n",
       "      <td>N3</td>\n",
       "      <td>IIIC</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>63</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age   Race Marital Status T Stage  N Stage 6th Stage   \n",
       "0   68  White        Married       T1      N1       IIA  \\\n",
       "1   50  White        Married       T2      N2      IIIA   \n",
       "2   58  White       Divorced       T3      N3      IIIC   \n",
       "\n",
       "               differentiate Grade   A Stage  Tumor Size Estrogen Status   \n",
       "0      Poorly differentiated     3  Regional           4        Positive  \\\n",
       "1  Moderately differentiated     2  Regional          35        Positive   \n",
       "2  Moderately differentiated     2  Regional          63        Positive   \n",
       "\n",
       "  Progesterone Status  Regional Node Examined  Reginol Node Positive   \n",
       "0            Positive                      24                      1  \\\n",
       "1            Positive                      14                      5   \n",
       "2            Positive                      14                      7   \n",
       "\n",
       "   Survival Months Status  \n",
       "0               60  Alive  \n",
       "1               62  Alive  \n",
       "2               75  Alive  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Breast_Cancer.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'T Stage ': 'T Stage'}, inplace=True)\n",
    "df.isnull().sum()\n",
    "df[\"Grade\"].value_counts()\n",
    "df[\"Grade\"] = df[\"Grade\"].apply(lambda x: int(x.replace(\" anaplastic; Grade IV\", \"4\")))\n",
    "\n",
    "categorical_cols = ['Race', 'Marital Status', 'A Stage', 'T Stage', 'N Stage',\n",
    "                     '6th Stage', 'differentiate', 'Estrogen Status', 'Progesterone Status']\n",
    "numerical_cols = df[['Age', 'Tumor Size', 'Regional Node Examined', 'Reginol Node Positive', 'Survival Months', 'Grade']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outliers for Age:\n",
      "Series([], Name: Age, dtype: int64)\n",
      "Number of outliers in Age: 0\n",
      "\n",
      "Outliers for Tumor Size:\n",
      "289     140\n",
      "740     140\n",
      "894     133\n",
      "1007    140\n",
      "1512    140\n",
      "3965    140\n",
      "Name: Tumor Size, dtype: int64\n",
      "Number of outliers in Tumor Size: 6\n",
      "\n",
      "Outliers for Regional Node Examined:\n",
      "941     61\n",
      "2462    57\n",
      "3950    60\n",
      "Name: Regional Node Examined, dtype: int64\n",
      "Number of outliers in Regional Node Examined: 3\n",
      "\n",
      "Outliers for Reginol Node Positive:\n",
      "100     24\n",
      "219     27\n",
      "238     26\n",
      "288     28\n",
      "482     24\n",
      "522     28\n",
      "530     28\n",
      "535     24\n",
      "544     29\n",
      "550     31\n",
      "574     26\n",
      "633     46\n",
      "662     27\n",
      "838     33\n",
      "909     29\n",
      "922     27\n",
      "989     37\n",
      "1039    28\n",
      "1116    24\n",
      "1120    30\n",
      "1128    37\n",
      "1199    27\n",
      "1246    26\n",
      "1267    35\n",
      "1382    25\n",
      "1411    24\n",
      "1567    29\n",
      "1667    29\n",
      "1711    25\n",
      "1872    26\n",
      "2028    29\n",
      "2031    27\n",
      "2142    32\n",
      "2182    41\n",
      "2287    26\n",
      "2293    28\n",
      "2425    28\n",
      "2568    26\n",
      "2638    28\n",
      "2755    26\n",
      "2928    30\n",
      "2934    34\n",
      "3017    34\n",
      "3265    33\n",
      "3401    24\n",
      "3601    24\n",
      "3646    26\n",
      "3677    26\n",
      "3822    26\n",
      "3840    24\n",
      "3893    32\n",
      "3898    29\n",
      "3915    25\n",
      "3960    27\n",
      "Name: Reginol Node Positive, dtype: int64\n",
      "Number of outliers in Reginol Node Positive: 54\n",
      "\n",
      "Outliers for Survival Months:\n",
      "Series([], Name: Survival Months, dtype: int64)\n",
      "Number of outliers in Survival Months: 0\n",
      "\n",
      "Outliers for Grade:\n",
      "Series([], Name: Grade, dtype: int64)\n",
      "Number of outliers in Grade: 0\n"
     ]
    }
   ],
   "source": [
    "def identify_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.1)\n",
    "    Q3 = df[column].quantile(0.9)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] < lower_limit) | (df[column] > upper_limit)]\n",
    "\n",
    "# Define a function to remove outliers using IQR method\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.1)\n",
    "    Q3 = df[column].quantile(0.9)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_limit) & (df[column] <= upper_limit)]\n",
    "\n",
    "# Print the outliers for each numerical column\n",
    "for column in numerical_cols.columns:\n",
    "    outliers = identify_outliers(numerical_cols, column)\n",
    "    print(f\"\\nOutliers for {column}:\")\n",
    "    print(outliers[column])\n",
    "    print(f\"Number of outliers in {column}: {len(outliers)}\")\n",
    "\n",
    "# Remove the outliers\n",
    "for column in numerical_cols.columns:\n",
    "    numerical_cols = remove_outliers(numerical_cols, column)\n",
    "\n",
    "# Encode the categorical columns\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded_cols = pd.DataFrame(onehot_encoder.fit_transform(df[categorical_cols]))\n",
    "encoded_cols.columns = onehot_encoder.get_feature_names_out()\n",
    "\n",
    "# Concatenate the dataframes\n",
    "df_encoded = pd.concat([numerical_cols.reset_index(drop=True), \n",
    "                        encoded_cols.reset_index(drop=True), \n",
    "                        df[\"Status\"].reset_index(drop=True)], \n",
    "                        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StandardScaler to normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df_encoded[['Age', 'Tumor Size', 'Regional Node Examined', 'Reginol Node Positive', 'Survival Months', 'Grade']] = scaler.fit_transform(\n",
    "    df_encoded[['Age', 'Tumor Size', 'Regional Node Examined', 'Reginol Node Positive', 'Survival Months', 'Grade']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping NA: 4024\n",
      "Number of rows after dropping NA: 3961\n",
      "Number of rows dropped: 63\n"
     ]
    }
   ],
   "source": [
    "# Count number of rows before dropping NA\n",
    "num_rows_before = df_encoded.shape[0]\n",
    "df_encoded = df_encoded.dropna()\n",
    "num_rows_after = df_encoded.shape[0]\n",
    "\n",
    "print(f\"Number of rows before dropping NA: {num_rows_before}\")\n",
    "print(f\"Number of rows after dropping NA: {num_rows_after}\")\n",
    "print(f\"Number of rows dropped: {num_rows_before - num_rows_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# remove Survival Months\n",
    "X = df_encoded.drop(['Status', 'Survival Months'], axis=1)\n",
    "y = df_encoded['Status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status\n",
       "Alive    3354\n",
       "Dead      607\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Alive       0.85      0.85      0.85       672\n",
      "        Dead       0.17      0.17      0.17       121\n",
      "\n",
      "    accuracy                           0.75       793\n",
      "   macro avg       0.51      0.51      0.51       793\n",
      "weighted avg       0.75      0.75      0.75       793\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[572 100]\n",
      " [100  21]]\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Assume you have X and y from your dataset\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create an SVC classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring='f1_macro')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best classifier from the grid search\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Alive       0.86      0.81      0.83       672\n",
      "        Dead       0.20      0.26      0.23       121\n",
      "\n",
      "    accuracy                           0.73       793\n",
      "   macro avg       0.53      0.54      0.53       793\n",
      "weighted avg       0.76      0.73      0.74       793\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[545 127]\n",
      " [ 89  32]]\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring='f1_macro')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best classifier from the grid search\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Alive       0.86      0.93      0.89       672\n",
      "        Dead       0.30      0.17      0.22       121\n",
      "\n",
      "    accuracy                           0.81       793\n",
      "   macro avg       0.58      0.55      0.56       793\n",
      "weighted avg       0.78      0.81      0.79       793\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[624  48]\n",
      " [100  21]]\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring='f1_macro')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best classifier from the grid search\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes + Random Over Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Alive       0.89      0.84      0.87       672\n",
      "        Dead       0.33      0.45      0.38       121\n",
      "\n",
      "    accuracy                           0.78       793\n",
      "   macro avg       0.61      0.64      0.62       793\n",
      "weighted avg       0.81      0.78      0.79       793\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[564 108]\n",
      " [ 67  54]]\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply Random OverSampler to the training set\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1_macro')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best classifier from the grid search\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Wrap everything with Random Over Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def perform_classification(X, y, classifier, param_grid, scoring='f1_macro'):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Apply Random OverSampler to the training set\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring=scoring)\n",
    "    grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Get the best classifier from the grid search\n",
    "    best_clf = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print the classification report and confusion matrix\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_mat)\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(\"\\nBest Hyperparameters:\")\n",
    "    print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Alive       0.85      0.81      0.83       672\n",
      "        Dead       0.17      0.21      0.19       121\n",
      "\n",
      "    accuracy                           0.72       793\n",
      "   macro avg       0.51      0.51      0.51       793\n",
      "weighted avg       0.75      0.72      0.73       793\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[546 126]\n",
      " [ 95  26]]\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Alive       0.87      0.86      0.87       672\n",
      "        Dead       0.25      0.26      0.26       121\n",
      "\n",
      "    accuracy                           0.77       793\n",
      "   macro avg       0.56      0.56      0.56       793\n",
      "weighted avg       0.77      0.77      0.77       793\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[581  91]\n",
      " [ 90  31]]\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Alive       0.86      0.92      0.89       672\n",
      "        Dead       0.30      0.19      0.23       121\n",
      "\n",
      "    accuracy                           0.81       793\n",
      "   macro avg       0.58      0.56      0.56       793\n",
      "weighted avg       0.78      0.81      0.79       793\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[619  53]\n",
      " [ 98  23]]\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Define the parameter grids for each classifier\n",
    "svc_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "dt_param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "\n",
    "svc_classifier = SVC()\n",
    "perform_classification(X, y, svc_classifier, svc_param_grid)\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "perform_classification(X, y, dt_classifier, dt_param_grid)\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "perform_classification(X, y, rf_classifier, rf_param_grid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mudKernel",
   "language": "python",
   "name": "mudkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
